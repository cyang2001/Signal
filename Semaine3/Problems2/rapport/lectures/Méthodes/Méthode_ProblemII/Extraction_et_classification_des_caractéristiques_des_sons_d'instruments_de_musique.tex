Dans le domaine de l'analyse audio numérique, l'extraction des caractéristiques sonores des instruments de musique est essentielle pour la recherche d'informations musicales et la classification des instruments. Nous avons étudié trois caractéristiques clés : le centroïde spectral, le taux de croisements par zéro et l'enveloppe ADSR, ainsi que leur application dans l'identification des types d'instruments.

\textbf{Le centroïde spectral}\footnote{\href{https://en.wikipedia.org/wiki/Spectral_centroid}{Cliquez ici pour accéder à la source sur le centroïde spectral}} décrit le centre de gravité du spectre sonore, reflétant la « brillance » du son. Sa représentation mathématique est la suivante : 
\begin{equation}
    C = \frac{\sum_{n=0}^{N-1}f(n)\cdot S(n)}{\sum_{n=0}^{N-1}S(n)} 
\end{equation}
où :
\begin{itemize}
    \item \(f(n)\) représente la fréquence
    \item \(S(n)\) l'amplitude correspondante à cette fréquence
\end{itemize}

\textbf{Le taux de croisements par zéro} \footnote{\href{https://en.wikipedia.org/wiki/Zero-crossing_rate}{Cliquez ici pour accéder à la source sur le taux de croisements par zéro}}mesure la fréquence à laquelle la forme d'onde du signal traverse l'axe temporel, et est liée à la hauteur et au timbre du son. Sa formule de calcul est la suivante :
\begin{equation}
    ZCR = \frac{1}{T-1}\sum_{t=1}^{T-1}\frac{1}{2}|\text{sgn}(s(t))-\text{sgn}(s(t-1))|
\end{equation}

\textbf{L'enveloppe ADSR }\footnote{\href{https://en.wikipedia.org/wiki/Envelope_(music)}{Cliquez ici pour accéder à la source de l'enveloppe ADSR}}analyse les variations dynamiques temporelles du son, où chaque phase est définie comme suit :
\begin{itemize}
    \item \textbf{Attack Time(A) :}
\end{itemize}
\begin{equation}
    A = \min \{t|s(t)\geq0.9 \cdot P_{peak}, t\in [0, \frac{T}{f_s}]\}
\end{equation}
\begin{itemize}
    \item \textbf{Decay Time(D) :}
\end{itemize}
\begin{equation}
    D = \min \{t|s(t)\leq S_{level}, t\in [A, \frac{T}{f_s}] - A\}
\end{equation}
\begin{itemize}
    \item \textbf{Sustain Level (S) :}
\end{itemize}
\begin{equation}
    S = \alpha \cdot P_{peak}
\end{equation}
Où :
\begin{description}
    \item \(\alpha\) est un pourcentage de l'amplitude maximale
    \item \(P_{peak}\) est l'amplitude maximale du signal
\end{description}
\begin{itemize}
    \item \textbf{Release Time (R) :}
\end{itemize}
\begin{equation}
    R = \min \{t |s(t) \leq \beta \cdot P_{initial}, t \in [t_{end}, \frac{T}{f_s}]  \} - t_{end}
\end{equation}
Où :
\begin{description}
    \item \(\beta\) est le coefficient qui détermine le seuil d'extinction sonore
    \item \(P_{initial}\) est l'amplitude au début de la phase de libération
    \item \(t_{end}\) est le point où la note se termine
    \item \(T\) est la taille totale de l'échantillon
    \item \(f_s\) est le taux d'échantillonnage
\end{description}

À travers ces caractéristiques, nous avons tenté de classer les instruments de musique. Cependant, nous avons constaté que les résultats de classification n'étaient pas idéaux. Les principales raisons en sont le choix arbitraire des seuils de caractéristiques, la possible superposition des caractéristiques entre différents instruments, ainsi que la complexité due à la diversité des échantillons.

Compte tenu de ces défis, nous estimons qu'il serait plus approprié d'utiliser des méthodes d'apprentissage automatique pour la classification des instruments. L'apprentissage machine, en particulier les techniques d'apprentissage profond, peut automatiquement apprendre des caractéristiques complexes pour distinguer les instruments à partir de grandes quantités de données. Ces méthodes réduisent non seulement le besoin de fixer manuellement des seuils, mais elles permettent également, en apprenant les modèles intrinsèques dans les données, d'améliorer la précision et la capacité de généralisation de la classification.